{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSI_ISE\\dsiis_env\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_5']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 3.8418 - val_loss: 3.7527\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5551 - val_loss: 3.0053\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5768 - val_loss: 2.7110\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1657 - val_loss: 2.5606\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8869 - val_loss: 2.5835\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9720 - val_loss: 2.6152\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6055 - val_loss: 2.5980\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6885 - val_loss: 2.6330\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7181 - val_loss: 2.6826\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7170 - val_loss: 2.7124\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5802 - val_loss: 2.7534\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4622 - val_loss: 2.8141\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4790 - val_loss: 2.8497\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2435 - val_loss: 2.8787\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4123 - val_loss: 2.9794\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3844 - val_loss: 3.0187\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6239 - val_loss: 2.9902\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3301 - val_loss: 3.2371\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0722 - val_loss: 3.1451\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2014 - val_loss: 3.2772\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3540 - val_loss: 3.3267\n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9726 - val_loss: 3.4438\n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1254 - val_loss: 3.4492\n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8597 - val_loss: 3.6786\n",
      "Epoch 25/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8756 - val_loss: 3.8674\n",
      "Epoch 26/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0704 - val_loss: 3.7502\n",
      "Epoch 27/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8731 - val_loss: 3.8724\n",
      "Epoch 28/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0291 - val_loss: 4.0289\n",
      "Epoch 29/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8187 - val_loss: 4.0291\n",
      "Epoch 30/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6988 - val_loss: 4.2439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSI_ISE\\dsiis_env\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_5', 'keras_tensor_11', 'keras_tensor_12']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Original sentence: nice\n",
      "Translated sentence: bonjour\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Simple dataset for demonstration\n",
    "\n",
    "data = [\n",
    "    \"hello \\t bonjour\",\n",
    "    \"how are you \\t comment ça va\",\n",
    "    \"good morning \\t bonjour\",\n",
    "    \"thank you \\t merci\",\n",
    "    \"good night \\t bonne nuit\",\n",
    "    \"goodbye \\t au revoir\",\n",
    "    \"please \\t s'il vous plaît\",\n",
    "    \"yes \\t oui\",\n",
    "    \"no \\t non\",\n",
    "    \"good evening \\t bonsoir\",\n",
    "    \"what is your name \\t comment vous appelez-vous\",\n",
    "    \"nice to meet you \\t enchanté\",\n",
    "    \"excuse me \\t excusez-moi\",\n",
    "    \"I'm sorry \\t je suis désolé\",\n",
    "    \"I love you \\t je t'aime\",\n",
    "    \"see you soon \\t à bientôt\",\n",
    "    \"take care \\t prends soin de toi\",\n",
    "    \"have a good day \\t bonne journée\",\n",
    "    \"where are you from \\t d'où viens-tu\",\n",
    "    \"I am fine \\t je vais bien\",\n",
    "    \"do you speak English \\t parlez-vous anglais\",\n",
    "    \"I don't understand \\t je ne comprends pas\",\n",
    "    \"help \\t aide\",\n",
    "    \"I'm hungry \\t j'ai faim\",\n",
    "    \"I'm thirsty \\t j'ai soif\",\n",
    "    \"what time is it \\t quelle heure est-il\",\n",
    "]\n",
    "# Prepare the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "for line in data:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    input_texts.append(input_text.strip())\n",
    "    target_texts.append(f\"start {target_text.strip()} end\")\n",
    "\n",
    "# Tokenize input and target texts\n",
    "input_tokenizer = Tokenizer(filters='')\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "max_length_input = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_length_input, padding='post')\n",
    "\n",
    "target_tokenizer = Tokenizer(filters='')\n",
    "target_tokenizer.fit_on_texts(target_texts)\n",
    "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "max_length_target = max(len(seq) for seq in target_sequences)\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_length_target, padding='post')\n",
    "\n",
    "# Prepare data for decoder\n",
    "decoder_input_data = target_sequences[:, :-1]\n",
    "decoder_target_data = target_sequences[:, 1:]\n",
    "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n",
    "\n",
    "# Model parameters\n",
    "embedding_dim = 64\n",
    "latent_dim = 128\n",
    "\n",
    "# Encoder model\n",
    "encoder_inputs = Input(shape=(max_length_input,))\n",
    "encoder_embedding = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder model\n",
    "decoder_inputs = Input(shape=(max_length_target - 1,))\n",
    "decoder_embedding = Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Seq2Seq model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit([input_sequences, decoder_input_data], decoder_target_data, batch_size=2, epochs=30, validation_split=0.2)\n",
    "\n",
    "# Inference models for testing\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Translation function\n",
    "def translate_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_tokenizer.word_index['start']\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_tokenizer.index_word.get(sampled_token_index)\n",
    "        if sampled_word == 'end' or sampled_word is None or len(decoded_sentence.split()) > max_length_target:\n",
    "            break\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Test translation\n",
    "test_sentence = \"nice\"\n",
    "test_sequence = pad_sequences(input_tokenizer.texts_to_sequences([test_sentence]), maxlen=max_length_input)\n",
    "translated_sentence = translate_sequence(test_sequence)\n",
    "print(f\"Original sentence: {test_sentence}\")\n",
    "print(f\"Translated sentence: {translated_sentence}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsiis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
