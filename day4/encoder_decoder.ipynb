{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes a sequence of numbers (e.g., [1, 2, 3]) as input and outputs the reversed sequence (e.g., [3, 2, 1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSI_ISE\\dsiis_env\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_75', 'keras_tensor_79']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1528 - loss: 2.2898 \n",
      "Epoch 2/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2303 - loss: 2.2316\n",
      "Epoch 3/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2891 - loss: 2.1307\n",
      "Epoch 4/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3187 - loss: 1.9397\n",
      "Epoch 5/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3678 - loss: 1.7179\n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3815 - loss: 1.5430\n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3999 - loss: 1.4626\n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4315 - loss: 1.3780\n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4660 - loss: 1.2914\n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5129 - loss: 1.2088\n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5629 - loss: 1.1276\n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6158 - loss: 1.0511\n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6746 - loss: 0.9683\n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7325 - loss: 0.8866\n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.7892\n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 0.7102\n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8566 - loss: 0.6346\n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8822 - loss: 0.5866\n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9059 - loss: 0.5204\n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9310 - loss: 0.4629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSI_ISE\\dsiis_env\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_79', 'keras_tensor_84', 'keras_tensor_85']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Input sequence: [8 3 7 5 9]\n",
      "Decoded sequence: [np.int64(9), np.int64(5), np.int64(7), np.int64(8), np.int64(3)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Generate the data\n",
    "num_samples = 1000  # Number of sequences\n",
    "input_length = 5     # Length of each input sequence\n",
    "input_vocab_size = 10  # Vocabulary size (digits 0-9)\n",
    "\n",
    "# Generate random input sequences\n",
    "input_sequences = np.random.randint(1, input_vocab_size, (num_samples, input_length))\n",
    "target_sequences = np.flip(input_sequences, axis=1)  # Reverse the sequences for the target\n",
    "\n",
    "# One-hot encode the input and target sequences\n",
    "input_onehot = np.eye(input_vocab_size)[input_sequences]  # (num_samples, input_length, input_vocab_size)\n",
    "target_onehot = np.eye(input_vocab_size)[target_sequences]\n",
    "\n",
    "# Prepare decoder input sequences (shifted target sequences)\n",
    "decoder_input_sequences = np.zeros_like(target_onehot)\n",
    "decoder_input_sequences[:, 1:, :] = target_onehot[:, :-1, :]  # Shift target sequences to the right\n",
    "decoder_input_sequences[:, 0, :] = 0  # Set <start> token as all zeros\n",
    "\n",
    "# Define the Encoder\n",
    "encoder_inputs = Input(shape=(None, input_vocab_size))\n",
    "encoder_lstm = LSTM(64, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the Decoder\n",
    "decoder_inputs = Input(shape=(None, input_vocab_size))\n",
    "decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(input_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the full model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([input_onehot, decoder_input_sequences], target_onehot, epochs=20, batch_size=64, verbose=1)\n",
    "\n",
    "# Define the inference models (for prediction)\n",
    "# Encoder model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder model\n",
    "decoder_state_input_h = Input(shape=(64,))\n",
    "decoder_state_input_c = Input(shape=(64,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Function to decode a sequence\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input sequence to get the states\n",
    "    states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Create an empty target sequence with a <start> token (all zeros)\n",
    "    target_seq = np.zeros((1, 1, input_vocab_size))\n",
    "\n",
    "    # Initialize the decoded sequence\n",
    "    decoded_sequence = []\n",
    "\n",
    "    # Generate tokens one-by-one\n",
    "    for _ in range(input_length):\n",
    "        # Predict the next token\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states)\n",
    "\n",
    "        # Get the token with the highest probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        decoded_sequence.append(sampled_token_index)\n",
    "\n",
    "        # Update the target sequence (input to the next step of the decoder)\n",
    "        target_seq = np.zeros((1, 1, input_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1\n",
    "\n",
    "        # Update the decoder's states\n",
    "        states = [h, c]\n",
    "\n",
    "    return decoded_sequence\n",
    "\n",
    "# Test the model with a new input\n",
    "test_sequence = np.random.randint(1, input_vocab_size, (1, input_length))  # Single test sequence\n",
    "test_sequence_onehot = np.eye(input_vocab_size)[test_sequence]  # One-hot encode the input\n",
    "decoded_output = decode_sequence(test_sequence_onehot)\n",
    "\n",
    "# Print the results\n",
    "print(\"Input sequence:\", test_sequence[0])  # Original input sequence\n",
    "print(\"Decoded sequence:\", decoded_output)  # Reversed sequence predicted by the model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsiis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
